{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adammajczyk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/adammajczyk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from classes import Word2VecModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "model_w2v_settings = return_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = Word2VecModel(model_w2v_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_clickbait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  is_clickbait\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...             1\n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...             0\n",
       "2                  Why the Truth Might Get You Fired             1\n",
       "3  15 Civilians Killed In Single US Airstrike Hav...             1\n",
       "4  Iranian woman jailed for fictional unpublished...             1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read merged data\n",
    "df = pd.read_csv('data/merged_titles_labels.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "title_vectors = [get_word_vectors(model_w2v, title, aggregation='mean') for title in df['title']]\n",
    "\n",
    "X = np.vstack(title_vectors)\n",
    "y = df['is_clickbait'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test stratified by y\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42, shuffle=True)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# save scaled data as csv if data does not exist yet\n",
    "if not os.path.exists('data/X_train.csv'):\n",
    "    np.savetxt('data/X_train.csv', X_train_scaled, delimiter=',')\n",
    "    np.savetxt('data/X_test.csv', X_test_scaled, delimiter=',')\n",
    "    np.savetxt('data/y_train.csv', y_train, delimiter=',')\n",
    "    np.savetxt('data/y_test.csv', y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7832694468565332\n",
      "F1:  0.7392190152801358\n"
     ]
    }
   ],
   "source": [
    "# train sample model for now\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predict on test data\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "\n",
    "# calculate auc and f1\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "print('AUC: ', roc_auc_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/adammajczyk/Sem7/inzynierka/pracaInzynierska/train_predictive_models.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adammajczyk/Sem7/inzynierka/pracaInzynierska/train_predictive_models.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m preprocess_title(temp_df[\u001b[39m'\u001b[39;49m\u001b[39mtitle\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[0;32m~/Sem7/inzynierka/pracaInzynierska/functions.py:81\u001b[0m, in \u001b[0;36mpreprocess_title\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_title\u001b[39m(df):\n\u001b[1;32m     80\u001b[0m     \u001b[39m# remove punctuation and other stuff\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mtitle\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mapply(replace_numbers_with_words)\n\u001b[1;32m     82\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(remove_punct)\n\u001b[1;32m     83\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(remove_possesive_s)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[wont, believe, celebrity]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title\n",
       "0  [wont, believe, celebrity]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.DataFrame({'title': ['You won\\'t believe what this celebrity did!']})\n",
    "\n",
    "preprocess_title(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run functions.py\n",
    "\n",
    "# preprocess_title(temp_df)\n",
    "\n",
    "get_word_vectors(model_w2v, preprocess_title(temp_df), aggregation='mean')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " 'e': 1,\n",
       " 'a': 2,\n",
       " 'o': 3,\n",
       " 'i': 4,\n",
       " 'r': 5,\n",
       " 'n': 6,\n",
       " 't': 7,\n",
       " 's': 8,\n",
       " 'l': 9,\n",
       " 'h': 10,\n",
       " 'd': 11,\n",
       " 'u': 12,\n",
       " 'c': 13,\n",
       " 'm': 14,\n",
       " 'T': 15,\n",
       " 'g': 16,\n",
       " 'p': 17,\n",
       " 'y': 18,\n",
       " 'f': 19,\n",
       " 'S': 20,\n",
       " 'A': 21,\n",
       " 'w': 22,\n",
       " 'k': 23,\n",
       " 'b': 24,\n",
       " 'C': 25,\n",
       " 'v': 26,\n",
       " 'W': 27,\n",
       " 'B': 28,\n",
       " 'P': 29,\n",
       " 'I': 30,\n",
       " 'M': 31,\n",
       " 'F': 32,\n",
       " 'H': 33,\n",
       " 'N': 34,\n",
       " 'D': 35,\n",
       " 'R': 36,\n",
       " 'O': 37,\n",
       " 'Y': 38,\n",
       " '-': 39,\n",
       " 'L': 40,\n",
       " 'E': 41,\n",
       " \"'\": 42,\n",
       " 'G': 43,\n",
       " ',': 44,\n",
       " '’': 45,\n",
       " ':': 46,\n",
       " 'U': 47,\n",
       " '1': 48,\n",
       " '.': 49,\n",
       " '0': 50,\n",
       " '2': 51,\n",
       " 'K': 52,\n",
       " 'x': 53,\n",
       " 'V': 54,\n",
       " 'J': 55,\n",
       " '\"': 56,\n",
       " 'z': 57,\n",
       " '5': 58,\n",
       " '‘': 59,\n",
       " 'j': 60,\n",
       " '?': 61,\n",
       " '7': 62,\n",
       " '3': 63,\n",
       " '6': 64,\n",
       " '9': 65,\n",
       " 'q': 66,\n",
       " '4': 67,\n",
       " '8': 68,\n",
       " 'Q': 69,\n",
       " '\\xa0': 70,\n",
       " 'Z': 71,\n",
       " '!': 72,\n",
       " '$': 73,\n",
       " 'о': 74,\n",
       " '–': 75,\n",
       " '”': 76,\n",
       " '“': 77,\n",
       " '(': 78,\n",
       " ')': 79,\n",
       " 'е': 80,\n",
       " '&': 81,\n",
       " 'и': 82,\n",
       " 'а': 83,\n",
       " 'н': 84,\n",
       " '|': 85,\n",
       " '/': 86,\n",
       " 'X': 87,\n",
       " 'т': 88,\n",
       " '—': 89,\n",
       " 'р': 90,\n",
       " 'с': 91,\n",
       " ';': 92,\n",
       " 'в': 93,\n",
       " '%': 94,\n",
       " 'л': 95,\n",
       " '*': 96,\n",
       " 'к': 97,\n",
       " '…': 98,\n",
       " 'é': 99,\n",
       " ']': 100,\n",
       " '[': 101,\n",
       " 'п': 102,\n",
       " '#': 103,\n",
       " 'д': 104,\n",
       " 'у': 105,\n",
       " 'м': 106,\n",
       " 'з': 107,\n",
       " 'ا': 108,\n",
       " 'б': 109,\n",
       " 'ы': 110,\n",
       " 'г': 111,\n",
       " 'я': 112,\n",
       " 'ь': 113,\n",
       " '+': 114,\n",
       " 'á': 115,\n",
       " 'ل': 116,\n",
       " 'â': 117,\n",
       " 'й': 118,\n",
       " '£': 119,\n",
       " 'ч': 120,\n",
       " '>': 121,\n",
       " '\\x80': 122,\n",
       " 'م': 123,\n",
       " '©': 124,\n",
       " 'ي': 125,\n",
       " 'С': 126,\n",
       " 'ó': 127,\n",
       " 'ж': 128,\n",
       " 'ر': 129,\n",
       " 'Н': 130,\n",
       " 'ц': 131,\n",
       " 'ш': 132,\n",
       " 'ن': 133,\n",
       " '\\x94': 134,\n",
       " 'و': 135,\n",
       " 'х': 136,\n",
       " 'ü': 137,\n",
       " 'í': 138,\n",
       " '»': 139,\n",
       " 'Р': 140,\n",
       " 'В': 141,\n",
       " 'П': 142,\n",
       " 'А': 143,\n",
       " 'К': 144,\n",
       " 'ю': 145,\n",
       " 'ب': 146,\n",
       " 'ä': 147,\n",
       " 'ة': 148,\n",
       " '€': 149,\n",
       " 'ت': 150,\n",
       " '«': 151,\n",
       " 'ñ': 152,\n",
       " 'ö': 153,\n",
       " 'س': 154,\n",
       " '~': 155,\n",
       " '\\x99': 156,\n",
       " 'Т': 157,\n",
       " 'ع': 158,\n",
       " 'ه': 159,\n",
       " 'ق': 160,\n",
       " 'ç': 161,\n",
       " 'à': 162,\n",
       " 'è': 163,\n",
       " 'М': 164,\n",
       " '@': 165,\n",
       " 'ح': 166,\n",
       " 'Д': 167,\n",
       " 'د': 168,\n",
       " 'ف': 169,\n",
       " 'ф': 170,\n",
       " '™': 171,\n",
       " 'ی': 172,\n",
       " 'Ш': 173,\n",
       " 'О': 174,\n",
       " 'И': 175,\n",
       " 'ج': 176,\n",
       " '·': 177,\n",
       " '\\x92': 178,\n",
       " 'ı': 179,\n",
       " '¿': 180,\n",
       " 'ß': 181,\n",
       " 'ك': 182,\n",
       " 'ú': 183,\n",
       " 'Ã': 184,\n",
       " 'α': 185,\n",
       " 'э': 186,\n",
       " 'Ч': 187,\n",
       " 'τ': 188,\n",
       " 'Е': 189,\n",
       " 'ο': 190,\n",
       " 'Б': 191,\n",
       " 'أ': 192,\n",
       " 'إ': 193,\n",
       " 'ش': 194,\n",
       " 'У': 195,\n",
       " 'З': 196,\n",
       " 'ι': 197,\n",
       " 'ć': 198,\n",
       " 'Х': 199,\n",
       " 'ğ': 200,\n",
       " 'щ': 201,\n",
       " 'ص': 202,\n",
       " 'ز': 203,\n",
       " 'خ': 204,\n",
       " 'ê': 205,\n",
       " 'ν': 206,\n",
       " '_': 207,\n",
       " 'ض': 208,\n",
       " 'λ': 209,\n",
       " 'ί': 210,\n",
       " 'υ': 211,\n",
       " 'ε': 212,\n",
       " 'Ф': 213,\n",
       " 'Э': 214,\n",
       " '=': 215,\n",
       " '`': 216,\n",
       " 'ط': 217,\n",
       " '•': 218,\n",
       " 'ã': 219,\n",
       " 'ş': 220,\n",
       " '¡': 221,\n",
       " 'É': 222,\n",
       " 'ρ': 223,\n",
       " 'Л': 224,\n",
       " 'ς': 225,\n",
       " 'κ': 226,\n",
       " 'Í': 227,\n",
       " 'ł': 228,\n",
       " 'ث': 229,\n",
       " '؟': 230,\n",
       " '\\n': 231,\n",
       " 'Â': 232,\n",
       " 'î': 233,\n",
       " 'ž': 234,\n",
       " '⋆': 235,\n",
       " 'ë': 236,\n",
       " 'ئ': 237,\n",
       " '\\x91': 238,\n",
       " 'آ': 239,\n",
       " '\\u200b': 240,\n",
       " 'œ': 241,\n",
       " 'Ü': 242,\n",
       " 'ø': 243,\n",
       " 'غ': 244,\n",
       " 'ذ': 245,\n",
       " 'Ю': 246,\n",
       " '×': 247,\n",
       " '\\x96': 248,\n",
       " 'Å': 249,\n",
       " '\\ue801': 250,\n",
       " 'σ': 251,\n",
       " 'Г': 252,\n",
       " 'ى': 253,\n",
       " 'η': 254,\n",
       " '„': 255,\n",
       " 'ń': 256,\n",
       " 'æ': 257,\n",
       " '🚨': 258,\n",
       " 'ス': 259,\n",
       " 'ę': 260,\n",
       " 'μ': 261,\n",
       " 'ゲ': 262,\n",
       " 'Я': 263,\n",
       " '÷': 264,\n",
       " 'Τ': 265,\n",
       " 'ъ': 266,\n",
       " '°': 267,\n",
       " 'バ': 268,\n",
       " '\\x93': 269,\n",
       " '▲': 270,\n",
       " '料': 271,\n",
       " 'گ': 272,\n",
       " '₹': 273,\n",
       " '³': 274,\n",
       " 'Á': 275,\n",
       " 'č': 276,\n",
       " '\\x9d': 277,\n",
       " '≠': 278,\n",
       " 'ؤ': 279,\n",
       " 'İ': 280,\n",
       " '®': 281,\n",
       " 'ό': 282,\n",
       " 'φ': 283,\n",
       " 'å': 284,\n",
       " 'Μ': 285,\n",
       " '{': 286,\n",
       " '}': 287,\n",
       " '′': 288,\n",
       " 'ک': 289,\n",
       " '夏': 290,\n",
       " '集': 291,\n",
       " '％': 292,\n",
       " 'は': 293,\n",
       " '作': 294,\n",
       " '人': 295,\n",
       " '特': 296,\n",
       " '気': 297,\n",
       " '春': 298,\n",
       " '新': 299,\n",
       " '布': 300,\n",
       " 'Γ': 301,\n",
       " 'で': 302,\n",
       " 'ầ': 303,\n",
       " 'ū': 304,\n",
       " 'ī': 305,\n",
       " 'Ś': 306,\n",
       " 'š': 307,\n",
       " 'Š': 308,\n",
       " 'ș': 309,\n",
       " 'ś': 310,\n",
       " 'º': 311,\n",
       " 'Ä': 312,\n",
       " 'ộ': 313,\n",
       " 'ủ': 314,\n",
       " 'ệ': 315,\n",
       " '通': 316,\n",
       " 'ị': 317,\n",
       " 'γ': 318,\n",
       " 'Ρ': 319,\n",
       " 'グ': 320,\n",
       " 'Ž': 321,\n",
       " 'ン': 322,\n",
       " 'イ': 323,\n",
       " 'レ': 324,\n",
       " '無': 325,\n",
       " '送': 326,\n",
       " '販': 327,\n",
       " '財': 328,\n",
       " 'Щ': 329,\n",
       " 'ッ': 330,\n",
       " '斯': 331,\n",
       " 'ء': 332,\n",
       " 'À': 333,\n",
       " '俄': 334,\n",
       " 'ά': 335,\n",
       " 'ϊ': 336,\n",
       " 'δ': 337,\n",
       " 'Α': 338,\n",
       " 'ή': 339,\n",
       " '罗': 340,\n",
       " 'Ç': 341,\n",
       " 'β': 342,\n",
       " 'Κ': 343,\n",
       " '总': 344,\n",
       " 'Χ': 345,\n",
       " '统': 346,\n",
       " '观': 347,\n",
       " 'έ': 348,\n",
       " '注': 349,\n",
       " 'ï': 350,\n",
       " '¢': 351,\n",
       " 'Σ': 352,\n",
       " 'ζ': 353,\n",
       " '\\u202f': 354,\n",
       " '˜': 355,\n",
       " '¸': 356,\n",
       " '\\u202c': 357,\n",
       " '\\x97': 358,\n",
       " '\\u202a': 359,\n",
       " '¦': 360,\n",
       " '\\u200e': 361,\n",
       " '±': 362,\n",
       " '\\x98': 363,\n",
       " '½': 364,\n",
       " 'ô': 365,\n",
       " 'Β': 366,\n",
       " 'õ': 367,\n",
       " 'ظ': 368,\n",
       " '‹': 369,\n",
       " 'Ş': 370,\n",
       " 'ё': 371,\n",
       " 'ـ': 372,\n",
       " '´': 373,\n",
       " '̈': 374,\n",
       " 'ύ': 375,\n",
       " 'Î': 376}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list words in model by .key_to_index\n",
    "model_w2v.model.wv.key_to_index\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4 0.6]]\n",
      "\n",
      "\n",
      "[[0.4 0.6]]\n",
      "\n",
      "\n",
      "[[0.4 0.6]]\n",
      "\n",
      "\n",
      "[[0.4 0.6]]\n",
      "\n",
      "\n",
      "[[0.4 0.6]]\n",
      "\n",
      "\n",
      "[[0.4 0.6]]\n",
      "\n",
      "\n",
      "[[0.4 0.6]]\n",
      "\n",
      "\n",
      "[[0.4 0.6]]\n",
      "\n",
      "\n",
      "[[0.4 0.6]]\n",
      "\n",
      "\n",
      "[[0.4 0.6]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_clickbait_examples = [\n",
    "    \"You won't believe what this celebrity did!\",\n",
    "    \"Shocking secrets revealed about the latest trend!\",\n",
    "    \"This simple trick will change your life forever!\",\n",
    "    \"Is this the craziest video on the internet?\",\n",
    "    \"10 unbelievable facts that will blow your mind!\",\n",
    "    \"You'll never guess what happened next!\",\n",
    "    \"Exclusive insider information on the hottest topic!\",\n",
    "    \"This product guarantees instant results – find out how!\",\n",
    "    \"What experts don't want you to know about...\",\n",
    "    \"Uncovered: The hidden truth behind a viral sensation!\",\n",
    "    \"The secret to getting rich overnight – revealed!\",\n",
    "    \"You'll be shocked by these before-and-after pictures!\",\n",
    "    \"The shocking reason why [common practice] is actually dangerous!\",\n",
    "    \"What [professionals/experts] don't want you to know about [subject] – it's revelatory!\",\n",
    "    \"Exposed: The truth behind [popular myth] – it will leave you flabbergasted!\",\n",
    "    \"You won't believe the results of this [year] experiment – it's mind-blowing!\",\n",
    "    \"The secret to [achievement] that [professionals/experts] keep quiet!\",\n",
    "    \"The surprising reason why [common belief] is actually a deception!\",\n",
    "    \"What [number]% of people regret about [life decision] – learn from their errors!\",\n",
    "    \"The ultimate hack for [common problem] – it's a game-changer!\",\n",
    "    \"Exposed: The dark side of [popular product] – it will leave you stunned!\",\n",
    "    \"This [year] trend is changing the way we [do something] – don't miss out!\",\n",
    "    \"What [professionals/experts] say about [hot topic] will blow your mind!\",\n",
    "    \"You won't believe the transformation of [ordinary person] – it's unbelievable!\",\n",
    "    \"The surprising link between [two seemingly unrelated things] – it's astonishing!\",\n",
    "    \"This simple trick will make you a [skill] expert in minutes!\",\n",
    "    \"Can you pass this impossible [topic] quiz? The results will astound you!\",\n",
    "    \"The shocking reason why [common practice] is actually dangerous!\",\n",
    "    \"What [professionals/experts] don't want you to know about [subject] – it's revelatory!\",\n",
    "    \"Exposed: The truth behind [popular myth] – it will leave you flabbergasted!\",\n",
    "    \"You won't believe the results of this [year] experiment – it's mind-blowing!\",\n",
    "    \"The secret to [achievement] that [professionals/experts] keep quiet!\",\n",
    "    \"The surprising reason why [common belief] is actually a deception!\",\n",
    "    \"What [number]% of people regret about [life decision] – learn from their errors!\",\n",
    "    \"The ultimate hack for [common problem] – it's a game-changer!\",\n",
    "    \"Exposed: The dark side of [popular product] – it will leave you stunned!\",\n",
    "    \"This [year] trend is changing the way we [do something] – don't miss out!\",\n",
    "    \"What [professionals/experts] say about [hot topic] will blow your mind!\",\n",
    "    \"You won't believe the transformation of [ordinary person] – it's unbelievable!\",]\n",
    "\n",
    "\n",
    "# get 10 random examples\n",
    "\n",
    "chat_clickbait_examples = np.random.choice(chat_clickbait_examples, 10)\n",
    "\n",
    "for example in chat_clickbait_examples:\n",
    "    print(predict_on_text(classifier, model_w2v , example))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4 0.6]]\n",
      "\n",
      "\n",
      "[[0.4 0.6]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "non_clickbait_titles = [\n",
    "    \"Wikinews interviews Tatton Spiller, founder of political news service Simple Politics\",\n",
    "    \"NASA's OSIRIS-REx arrives in Houston, US after returning asteroid samples to Earth\"]\n",
    "\n",
    "for example in non_clickbait_titles:\n",
    "    print(predict_on_text(classifier, model_w2v , example))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
