{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adammajczyk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/adammajczyk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_clickbait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  is_clickbait\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...             1\n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...             0\n",
       "2                  Why the Truth Might Get You Fired             1\n",
       "3  15 Civilians Killed In Single US Airstrike Hav...             1\n",
       "4  Iranian woman jailed for fictional unpublished...             1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read merged data\n",
    "df = pd.read_csv('data/merged_titles_labels.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(title, aggregation=None):\n",
    "    word_vectors = [model.wv[word] for word in title if word in model.wv]\n",
    "    # print(len(word_vectors))\n",
    "    # print(word_vectors)\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(VECTOR_SIZE)\n",
    "    elif aggregation == 'mean':\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    elif aggregation is None:\n",
    "        return word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "title_vectors = [get_word_vectors(title, aggregation='mean') for title in df['title']]\n",
    "\n",
    "X = np.vstack(title_vectors)\n",
    "y = df['is_clickbait'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test stratified by y\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42, shuffle=True)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# save scaled data as csv\n",
    "np.savetxt('data/X_train.csv', X_train_scaled, delimiter=',')\n",
    "np.savetxt('data/X_test.csv', X_test_scaled, delimiter=',')\n",
    "np.savetxt('data/y_train.csv', y_train, delimiter=',')\n",
    "np.savetxt('data/y_test.csv', y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost grid\n",
    "catboost_grid = {\n",
    "    'iterations': [100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'depth': [3, 4, 5, 6, 7, 8],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "# xgboost grid\n",
    "xgboost_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'gamma': [0, 1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# random forest grid\n",
    "random_forest_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# lightgbm grid\n",
    "lightgbm_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'num_leaves': [31, 62, 93, 124, 155, 186, 217, 248, 279, 310]\n",
    "}\n",
    "\n",
    "# knn grid\n",
    "knn_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gridsearchcv\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_text(text):\n",
    "    # print(text)\n",
    "    text = preprocess_title(pd.DataFrame({'title': [text]}))\n",
    "    text = get_word_vectors(text['title'][0], aggregation='mean')\n",
    "    # print(len(text))\n",
    "    return classifier.predict_proba(text)\n",
    "\n",
    "predict_on_text('19 Things You Don’t Know About Your Favorite Sports Teams')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
