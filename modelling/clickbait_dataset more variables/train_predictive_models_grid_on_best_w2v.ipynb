{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "%run '../functions.py'\n",
    "%run '../classes.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'grid_search_results_new.json'\n",
    "grids_path = '../grid_search_grids.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v_settings = return_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v_settings['model_path'] = '../all_datasets/' + model_w2v_settings['model_path']\n",
    "\n",
    "model_w2v = Word2VecModel(model_w2v_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read preprocessed data from pickle file\n",
    "df = pd.read_pickle('data/preprocessed_titles_labels.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sample'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test stratified by y\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "df['title_vector'] = [get_word_vectors(model_w2v, title, aggregation='mean') for title in df['title']]\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.63768053, -0.16730867,  1.2560811 ,  0.3338902 , -0.56454986,\n",
       "        0.44497627,  0.784385  ,  0.3551108 , -0.8828402 ,  0.59592795,\n",
       "        0.1280393 , -0.64912486,  0.81945324, -0.3996215 ,  0.32769346,\n",
       "        1.2330511 ,  0.67513835, -0.43883395,  0.24185432, -0.9126102 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_vector'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 6, 4, 12, 13, 19, 18, 16, 14, 11, 8, 9]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables_to_drop = get_dimensions_to_drop()\n",
    "variables_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_vector'] = [drop_dimensions_from_vector(vector, variables_to_drop) for vector in df['title_vector']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.63768053, -0.16730867,  1.2560811 ,  0.3338902 ,  0.44497627,\n",
       "        0.3551108 ,  1.2330511 , -0.43883395], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_vector'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack(df[df['sample']=='train']['title_vector'])\n",
    "X_test = np.vstack(df[df['sample']=='val2']['title_vector'])\n",
    "\n",
    "y_train = df[df['sample']=='train']['is_clickbait']\n",
    "y_test = df[df['sample']=='val2']['is_clickbait']\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(grids_path, 'r') as f:\n",
    "    model_settings = json.load(f)\n",
    "\n",
    "model_settings\n",
    "grids = model_settings['grid_search_grids']\n",
    "grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decision_tree', 'catboost', 'lightgbm', 'xgboost', 'random_forest']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_to_CV = list()\n",
    "\n",
    "for model_name, grid in grids.items():\n",
    "    # check if model has already been trained - if 'best_params' exists in grid\n",
    "    if 'best_params' in grid.keys():\n",
    "        print(f'Model {model_name} already trained')\n",
    "        continue\n",
    "    models_to_CV.append((model_name))\n",
    "models_to_CV\n",
    "\n",
    "# remove _grid from model names\n",
    "models_to_CV = [model_name.replace('_grid', '') for model_name in models_to_CV]\n",
    "models_to_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_model_with_param(model_name, param = dict()):\n",
    "    if model_name == 'decision_tree':\n",
    "        model = DecisionTreeClassifier(**param)\n",
    "    elif model_name == 'random_forest':\n",
    "        model = RandomForestClassifier(**param)\n",
    "    elif model_name == 'xgboost':\n",
    "        model = XGBClassifier(**param)\n",
    "    elif model_name == 'lightgbm':\n",
    "        model = LGBMClassifier(**param, verbose=-1)\n",
    "    elif model_name == 'catboost':\n",
    "        model = CatBoostClassifier(**param,verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_CV = [\n",
    "    'catboost',\n",
    "    'lightgbm', \n",
    "    'xgboost',\n",
    "    \n",
    "    'decision_tree', \n",
    "    'random_forest',  \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# read existing results\n",
    "try:\n",
    "    with open(save_path, 'r') as f:\n",
    "        grid_search_results = json.load(f)\n",
    "    print('Loaded existing results')\n",
    "except:\n",
    "    grid_search_results = dict()\n",
    "    print('No existing results found - creating new dict')\n",
    "for model_name in models_to_CV:\n",
    "    grid_search_results[model_name] = dict()\n",
    "\n",
    "for model_name in tqdm(models_to_CV, desc = 'Models'):\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # get grid\n",
    "    grid = grids[model_name+'_grid']\n",
    "\n",
    "    # generate all combinations of parameters\n",
    "    import itertools\n",
    "\n",
    "    keys, values = zip(*grid.items())\n",
    "    combinations_dicts = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "    # do grid search\n",
    "    \n",
    "    for params in combinations_dicts:\n",
    "        grid_search_results[model_name][str(params)] = dict()\n",
    "\n",
    "    for params in tqdm(combinations_dicts, desc = 'Grid combinations search for model {}'.format(model_name)):\n",
    "       \n",
    "        model = return_model_with_param(model_name, params)\n",
    "        scores_auc_cv_val = list()\n",
    "        scores_auc_val2 = list()\n",
    "        scores_auc_train = list()\n",
    "\n",
    "        scores_f1_cv_val = list()\n",
    "        scores_f1_val2 = list()\n",
    "        scores_f1_train = list()\n",
    "\n",
    "        for train_index, val_index in kf.split(X_train_scaled, y_train):\n",
    "            X_train_kf = X_train_scaled[train_index]\n",
    "            X_val_kf = X_train_scaled[val_index]\n",
    "            y_train_kf = y_train.iloc[train_index]\n",
    "            y_val_kf = y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_kf, y_train_kf)\n",
    "\n",
    "            # print(model)\n",
    "\n",
    "        \n",
    "            scores_auc_cv_val.append(roc_auc_score(y_val_kf, model.predict_proba(X_val_kf)[:,1]))\n",
    "            scores_auc_val2.append(roc_auc_score(y_test, model.predict_proba(X_test_scaled)[:,1]))\n",
    "            scores_auc_train.append(roc_auc_score(y_train_kf, model.predict_proba(X_train_kf)[:,1]))\n",
    "\n",
    "            y_pred_cv_val = model.predict_proba(X_val_kf)[:,1]\n",
    "            y_pred_val2 = model.predict_proba(X_test_scaled)[:,1]\n",
    "            y_pred_train = model.predict_proba(X_train_kf)[:,1]\n",
    "\n",
    "            # print(y_pred_cv_val[y_pred_cv_val>0.5])\n",
    "\n",
    "            y_pred_cv_val = np.where(y_pred_cv_val > 0.5, 1, 0)\n",
    "            y_pred_val2 = np.where(y_pred_val2 > 0.5, 1, 0)\n",
    "            y_pred_train = np.where(y_pred_train > 0.5, 1, 0)\n",
    "\n",
    "\n",
    "            \n",
    "            scores_f1_cv_val.append(f1_score(y_val_kf, model.predict(X_val_kf)))\n",
    "            scores_f1_val2.append(f1_score(y_test, model.predict(X_test_scaled)))\n",
    "            scores_f1_train.append(f1_score(y_train_kf, model.predict(X_train_kf)))\n",
    "            break\n",
    "\n",
    "        # print(scores_f1_train, scores_f1_cv_val, scores_f1_val2)\n",
    "        # print(scores_auc_train, scores_auc_cv_val, scores_auc_val2)\n",
    "\n",
    "        grid_search_results[model_name][str(params)]['mean_train_f1'] = np.mean(scores_f1_train)\n",
    "        grid_search_results[model_name][str(params)]['mean_cv_val_f1'] = np.mean(scores_f1_cv_val)\n",
    "        grid_search_results[model_name][str(params)]['mean_val2_f1'] = np.mean(scores_f1_val2)\n",
    "\n",
    "        grid_search_results[model_name][str(params)]['mean_train_auc'] = np.mean(scores_auc_train)\n",
    "        grid_search_results[model_name][str(params)]['mean_cv_val_auc'] = np.mean(scores_auc_cv_val)\n",
    "        grid_search_results[model_name][str(params)]['mean_val2_auc'] = np.mean(scores_auc_val2)\n",
    "\n",
    "        grid_search_results[model_name][str(params)]['f1_diff_cv_val'] = np.mean(scores_f1_train) - np.mean(scores_f1_cv_val)\n",
    "        grid_search_results[model_name][str(params)]['auc_diff_cv_val'] = np.mean(scores_auc_train) - np.mean(scores_auc_cv_val)\n",
    "\n",
    "        grid_search_results[model_name][str(params)]['f1_diff_val2'] = np.mean(scores_f1_train) - np.mean(scores_f1_val2)\n",
    "        grid_search_results[model_name][str(params)]['auc_diff_val2'] = np.mean(scores_auc_train) - np.mean(scores_auc_val2)\n",
    "\n",
    "        grid_search_results[model_name][str(params)]['params'] = params\n",
    "\n",
    "        # save results to json file\n",
    "        with open(save_path, 'w') as f:\n",
    "            json.dump(grid_search_results, f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    print(grid_search_results[model_name])\n",
    "    \n",
    "# grid_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "with open(save_path, 'w') as f:\n",
    "    json.dump(grid_search_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results\n",
    "with open(save_path, 'r') as f:\n",
    "    grid_search_results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res= pd.DataFrame()\n",
    "\n",
    "for model in grid_search_results:\n",
    "    temp = grid_search_results[model]\n",
    "    temp = pd.DataFrame.from_dict(temp)\n",
    "    temp = temp.transpose()\n",
    "    temp['model'] = model\n",
    "    df_res = pd.concat([df_res, temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = df_res.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_auc = df_res[(df_res['auc_diff_val2']<=0.05)].sort_values(by='mean_val2_auc', ascending=False).head(500)\n",
    "top_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topf1 = df_res[(df_res['f1_diff_val2']<=0.05)].sort_values(by='mean_val2_f1', ascending=False).head(500)\n",
    "topf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_both = pd.merge(top_auc, topf1, on=['index'], how='inner')\n",
    "\n",
    "# keep _x columns\n",
    "top_both = top_both[[col for col in top_both.columns if '_x' in col]]\n",
    "top_both.columns = [col.replace('_x', '') for col in top_both.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_cv_val_f1</th>\n",
       "      <th>mean_val2_f1</th>\n",
       "      <th>mean_train_auc</th>\n",
       "      <th>mean_cv_val_auc</th>\n",
       "      <th>mean_val2_auc</th>\n",
       "      <th>f1_diff_cv_val</th>\n",
       "      <th>auc_diff_cv_val</th>\n",
       "      <th>f1_diff_val2</th>\n",
       "      <th>auc_diff_val2</th>\n",
       "      <th>params</th>\n",
       "      <th>model</th>\n",
       "      <th>sum_diff_val2</th>\n",
       "      <th>sum_auc_f1_val2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952613</td>\n",
       "      <td>0.95778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988746</td>\n",
       "      <td>0.989432</td>\n",
       "      <td>0.047387</td>\n",
       "      <td>0.011254</td>\n",
       "      <td>0.04222</td>\n",
       "      <td>0.010568</td>\n",
       "      <td>{'n_estimators': 250, 'learning_rate': 0.2, 'm...</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.052787</td>\n",
       "      <td>1.947213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988469</td>\n",
       "      <td>0.951635</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.999448</td>\n",
       "      <td>0.989098</td>\n",
       "      <td>0.989551</td>\n",
       "      <td>0.036833</td>\n",
       "      <td>0.01035</td>\n",
       "      <td>0.031947</td>\n",
       "      <td>0.009897</td>\n",
       "      <td>{'n_estimators': 50, 'learning_rate': 0.2, 'ma...</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>1.946073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952066</td>\n",
       "      <td>0.954106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988705</td>\n",
       "      <td>0.990702</td>\n",
       "      <td>0.047934</td>\n",
       "      <td>0.011295</td>\n",
       "      <td>0.045894</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>{'n_estimators': 500, 'learning_rate': None, '...</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.055192</td>\n",
       "      <td>1.944808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952066</td>\n",
       "      <td>0.954106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988705</td>\n",
       "      <td>0.990702</td>\n",
       "      <td>0.047934</td>\n",
       "      <td>0.011295</td>\n",
       "      <td>0.045894</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>{'n_estimators': 500, 'learning_rate': 0.1, 'm...</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.055192</td>\n",
       "      <td>1.944808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951767</td>\n",
       "      <td>0.955368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987997</td>\n",
       "      <td>0.989354</td>\n",
       "      <td>0.048233</td>\n",
       "      <td>0.012003</td>\n",
       "      <td>0.044632</td>\n",
       "      <td>0.010646</td>\n",
       "      <td>{'n_estimators': 500, 'learning_rate': 0.2, 'm...</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.055278</td>\n",
       "      <td>1.944722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.98004</td>\n",
       "      <td>0.953076</td>\n",
       "      <td>0.951574</td>\n",
       "      <td>0.998091</td>\n",
       "      <td>0.989728</td>\n",
       "      <td>0.988913</td>\n",
       "      <td>0.026964</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>0.028466</td>\n",
       "      <td>0.009178</td>\n",
       "      <td>{'n_estimators': 100, 'learning_rate': 0.1, 'm...</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.037644</td>\n",
       "      <td>1.940487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.965586</td>\n",
       "      <td>0.953375</td>\n",
       "      <td>0.951574</td>\n",
       "      <td>0.994584</td>\n",
       "      <td>0.989774</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.012211</td>\n",
       "      <td>0.00481</td>\n",
       "      <td>0.014012</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>{'n_estimators': 100, 'learning_rate': 0.1, 'm...</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.019697</td>\n",
       "      <td>1.940474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.965586</td>\n",
       "      <td>0.953375</td>\n",
       "      <td>0.951574</td>\n",
       "      <td>0.994584</td>\n",
       "      <td>0.989774</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.012211</td>\n",
       "      <td>0.00481</td>\n",
       "      <td>0.014012</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>{'n_estimators': 100, 'learning_rate': 0.1, 'm...</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.019697</td>\n",
       "      <td>1.940474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.981665</td>\n",
       "      <td>0.953424</td>\n",
       "      <td>0.951691</td>\n",
       "      <td>0.998486</td>\n",
       "      <td>0.988779</td>\n",
       "      <td>0.988775</td>\n",
       "      <td>0.028241</td>\n",
       "      <td>0.009706</td>\n",
       "      <td>0.029974</td>\n",
       "      <td>0.009711</td>\n",
       "      <td>{'n_estimators': 100, 'learning_rate': 0.2, 'm...</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.039684</td>\n",
       "      <td>1.940466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.981665</td>\n",
       "      <td>0.953424</td>\n",
       "      <td>0.951691</td>\n",
       "      <td>0.998486</td>\n",
       "      <td>0.988779</td>\n",
       "      <td>0.988775</td>\n",
       "      <td>0.028241</td>\n",
       "      <td>0.009706</td>\n",
       "      <td>0.029974</td>\n",
       "      <td>0.009711</td>\n",
       "      <td>{'n_estimators': 100, 'learning_rate': 0.2, 'm...</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.039684</td>\n",
       "      <td>1.940466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_train_f1 mean_cv_val_f1 mean_val2_f1 mean_train_auc mean_cv_val_auc  \\\n",
       "0             1.0       0.952613      0.95778            1.0        0.988746   \n",
       "1        0.988469       0.951635     0.956522       0.999448        0.989098   \n",
       "2             1.0       0.952066     0.954106            1.0        0.988705   \n",
       "3             1.0       0.952066     0.954106            1.0        0.988705   \n",
       "4             1.0       0.951767     0.955368            1.0        0.987997   \n",
       "..            ...            ...          ...            ...             ...   \n",
       "187       0.98004       0.953076     0.951574       0.998091        0.989728   \n",
       "188      0.965586       0.953375     0.951574       0.994584        0.989774   \n",
       "189      0.965586       0.953375     0.951574       0.994584        0.989774   \n",
       "190      0.981665       0.953424     0.951691       0.998486        0.988779   \n",
       "191      0.981665       0.953424     0.951691       0.998486        0.988779   \n",
       "\n",
       "    mean_val2_auc f1_diff_cv_val auc_diff_cv_val f1_diff_val2 auc_diff_val2  \\\n",
       "0        0.989432       0.047387        0.011254      0.04222      0.010568   \n",
       "1        0.989551       0.036833         0.01035     0.031947      0.009897   \n",
       "2        0.990702       0.047934        0.011295     0.045894      0.009298   \n",
       "3        0.990702       0.047934        0.011295     0.045894      0.009298   \n",
       "4        0.989354       0.048233        0.012003     0.044632      0.010646   \n",
       "..            ...            ...             ...          ...           ...   \n",
       "187      0.988913       0.026964        0.008363     0.028466      0.009178   \n",
       "188        0.9889       0.012211         0.00481     0.014012      0.005684   \n",
       "189        0.9889       0.012211         0.00481     0.014012      0.005684   \n",
       "190      0.988775       0.028241        0.009706     0.029974      0.009711   \n",
       "191      0.988775       0.028241        0.009706     0.029974      0.009711   \n",
       "\n",
       "                                                params     model  \\\n",
       "0    {'n_estimators': 250, 'learning_rate': 0.2, 'm...  lightgbm   \n",
       "1    {'n_estimators': 50, 'learning_rate': 0.2, 'ma...  lightgbm   \n",
       "2    {'n_estimators': 500, 'learning_rate': None, '...  lightgbm   \n",
       "3    {'n_estimators': 500, 'learning_rate': 0.1, 'm...  lightgbm   \n",
       "4    {'n_estimators': 500, 'learning_rate': 0.2, 'm...  lightgbm   \n",
       "..                                                 ...       ...   \n",
       "187  {'n_estimators': 100, 'learning_rate': 0.1, 'm...   xgboost   \n",
       "188  {'n_estimators': 100, 'learning_rate': 0.1, 'm...   xgboost   \n",
       "189  {'n_estimators': 100, 'learning_rate': 0.1, 'm...   xgboost   \n",
       "190  {'n_estimators': 100, 'learning_rate': 0.2, 'm...   xgboost   \n",
       "191  {'n_estimators': 100, 'learning_rate': 0.2, 'm...   xgboost   \n",
       "\n",
       "    sum_diff_val2 sum_auc_f1_val2  \n",
       "0        0.052787        1.947213  \n",
       "1        0.041844        1.946073  \n",
       "2        0.055192        1.944808  \n",
       "3        0.055192        1.944808  \n",
       "4        0.055278        1.944722  \n",
       "..            ...             ...  \n",
       "187      0.037644        1.940487  \n",
       "188      0.019697        1.940474  \n",
       "189      0.019697        1.940474  \n",
       "190      0.039684        1.940466  \n",
       "191      0.039684        1.940466  \n",
       "\n",
       "[192 rows x 14 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_both['sum_diff_val2'] = top_both['f1_diff_val2'] + top_both['auc_diff_val2']\n",
    "top_both['sum_auc_f1_val2'] = top_both['mean_val2_f1'] + top_both['mean_val2_auc']\n",
    "\n",
    "top_both = top_both.sort_values(by='sum_auc_f1_val2', ascending=False).head(1000).reset_index(drop=True)\n",
    "top_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winner model: |lightgbm| with params: {'n_estimators': 250, 'learning_rate': 0.2, 'max_depth': 8, 'num_leaves': 93}\n"
     ]
    }
   ],
   "source": [
    "params, model_name = top_both['params'][0], top_both['model'][0]\n",
    "print('Winner model: |{}|'.format(model_name), 'with params: {}'.format(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.2, max_depth=8, n_estimators=250, num_leaves=93,\n",
       "               verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.2, max_depth=8, n_estimators=250, num_leaves=93,\n",
       "               verbose=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.2, max_depth=8, n_estimators=250, num_leaves=93,\n",
       "               verbose=-1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model with best params\n",
    "model = return_model_with_param(model_name, params)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "import pickle\n",
    "with open('predictive_models/{}.pkl'.format(model_name), 'wb') as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scaler\n",
    "with open('predictive_models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.9509011808576756\n",
      "AUC score: 0.988110506000508\n"
     ]
    }
   ],
   "source": [
    "# calculate metrics on test set\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "X_test = np.vstack(df[df['sample']=='test']['title_vector'])\n",
    "y_test = df[df['sample']=='test']['is_clickbait']\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "print('F1 score: {}'.format(f1_score(y_test, y_pred)))\n",
    "print('AUC score: {}'.format(roc_auc_score(y_test, y_pred_proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best threshold for f1 score\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "# find threshold for best f1 score\n",
    "thresholds = np.linspace(0, 1, 10000)\n",
    "f1s = dict()\n",
    "for threshold in tqdm(thresholds):\n",
    "    y_pred = (model.predict_proba(X_test_scaled)[:, 1] >= threshold).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f1s[threshold] = f1\n",
    "\n",
    "# get threshold for best f1 score\n",
    "threshold = max(f1s, key=f1s.get)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC test: 0.988110506000508\n",
      "F1 test: 0.9556527170518425\n",
      "Accuracy test: 0.955818294959552\n"
     ]
    }
   ],
   "source": [
    "# find auc and f1 for best threshold and accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = (model.predict_proba(X_test_scaled)[:, 1] >= threshold).astype(int)\n",
    "y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'ROC AUC test: {roc_auc}')\n",
    "print(f'F1 test: {f1}')\n",
    "print(f'Accuracy test: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC train: 1.0\n",
      "F1 train: 1.0\n",
      "Accuracy train: 1.0\n"
     ]
    }
   ],
   "source": [
    "# find auc and f1 for best threshold on train\n",
    "y_pred = (model.predict_proba(X_train_scaled)[:, 1] >= threshold).astype(int)\n",
    "y_proba = model.predict_proba(X_train_scaled)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_train, y_proba)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "print(f'ROC AUC train: {roc_auc}')\n",
    "print(f'F1 train: {f1}')\n",
    "print(f'Accuracy train: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save threshold to txt file\n",
    "with open('predictive_models/threshold.txt', 'w') as f:\n",
    "    f.write(str(threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_5', 'dim_7', 'dim_15',\n",
       "       'dim_17'], dtype='<U6')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_undropped_dimensions(dropped_dimensions, n_dim):\n",
    "    all_dimensions = list(range(n_dim))\n",
    "    undropped_dimensions = [dim for dim in all_dimensions if dim not in dropped_dimensions]\n",
    "    return undropped_dimensions\n",
    "\n",
    "undropped_dimensions = get_undropped_dimensions(variables_to_drop, 20)\n",
    "undropped_dimensions = [str('dim_'+str(dim)) for dim in undropped_dimensions]\n",
    "undropped_dimensions = np.array(undropped_dimensions)\n",
    "undropped_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=undropped_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 28836 rows 8 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 28836 values\n",
      "  -> model_class       : lightgbm.sklearn.LGBMClassifier (default)\n",
      "  -> label             : Champion Model\n",
      "  -> predict function  : <function yhat_proba_default at 0x2b9d737e0> will be used (default)\n",
      "  -> predict function  : Accepts pandas.DataFrame and numpy.ndarray.\n",
      "  -> predicted values  : min = 2.81e-10, mean = 0.498, max = 1.0\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.0711, mean = -2.77e-07, max = 0.0999\n",
      "  -> model_info        : package lightgbm\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "displaylogo": false,
        "modeBarButtonsToRemove": [
         "sendDataToCloud",
         "lasso2d",
         "autoScale2d",
         "select2d",
         "zoom2d",
         "pan2d",
         "zoomIn2d",
         "zoomOut2d",
         "resetScale2d",
         "toggleSpikelines",
         "hoverCompareCartesian",
         "hoverClosestCartesian"
        ],
        "plotlyServerURL": "https://plot.ly",
        "staticPlot": false,
        "toImageButtonOptions": {
         "height": null,
         "width": null
        }
       },
       "data": [
        {
         "base": 0,
         "hoverinfo": "text",
         "hoverlabel": {
          "bgcolor": "rgba(0,0,0,0.8)"
         },
         "hovertext": [
          "Model: Champion Model loss after<br>variable: dim_7 is permuted: 0.099<br>Drop-out loss change: +0.099",
          "Model: Champion Model loss after<br>variable: dim_5 is permuted: 0.076<br>Drop-out loss change: +0.076",
          "Model: Champion Model loss after<br>variable: dim_15 is permuted: 0.003<br>Drop-out loss change: +0.003",
          "Model: Champion Model loss after<br>variable: dim_17 is permuted: 0.002<br>Drop-out loss change: +0.002",
          "Model: Champion Model loss after<br>variable: dim_3 is permuted: 0.002<br>Drop-out loss change: +0.002",
          "Model: Champion Model loss after<br>variable: dim_2 is permuted: 0.001<br>Drop-out loss change: +0.001",
          "Model: Champion Model loss after<br>variable: dim_0 is permuted: 0.001<br>Drop-out loss change: +0.001",
          "Model: Champion Model loss after<br>variable: dim_1 is permuted: 0.001<br>Drop-out loss change: +0.001"
         ],
         "marker": {
          "color": "#46bac2"
         },
         "orientation": "h",
         "showlegend": false,
         "text": [
          "+0.099",
          "+0.076",
          "+0.003",
          "+0.002",
          "+0.002",
          "+0.001",
          "+0.001",
          "+0.001"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.09897457705602672,
          0.07550042893458107,
          0.0031080733728600317,
          0.002088810024673482,
          0.0020644366539226853,
          0.0008421745126661162,
          0.0007200875173562383,
          0.0005802920219522001
         ],
         "xaxis": "x",
         "y": [
          "dim_7",
          "dim_5",
          "dim_15",
          "dim_17",
          "dim_3",
          "dim_2",
          "dim_0",
          "dim_1"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Champion Model",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "drop-out loss",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0,
          "yanchor": "top",
          "yref": "paper",
          "yshift": -30
         }
        ],
        "font": {
         "color": "#371ea3"
        },
        "height": 343,
        "margin": {
         "b": 71,
         "r": 30,
         "t": 78
        },
        "shapes": [
         {
          "line": {
           "color": "#371ea3",
           "dash": "dot",
           "width": 1.5
          },
          "type": "line",
          "x0": 0,
          "x1": 0,
          "xref": "x",
          "y0": -1,
          "y1": 8,
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "scatter": [
           {
            "type": "scatter"
           }
          ]
         }
        },
        "title": {
         "text": "Variable Importance",
         "x": 0.15
        },
        "xaxis": {
         "anchor": "y",
         "automargin": true,
         "domain": [
          0,
          1
         ],
         "fixedrange": true,
         "gridwidth": 2,
         "range": [
          -0.014846186558404008,
          0.11382076361443072
         ],
         "tickcolor": "white",
         "ticklen": 3,
         "ticks": "outside",
         "type": "linear",
         "zeroline": false
        },
        "yaxis": {
         "anchor": "x",
         "automargin": true,
         "autorange": "reversed",
         "domain": [
          0,
          1
         ],
         "fixedrange": true,
         "gridwidth": 2,
         "tickcolor": "white",
         "ticklen": 10,
         "ticks": "outside",
         "type": "category"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dalex\n",
    "# Create an explainer object\n",
    "exp = dalex.Explainer(model, X_train_scaled_df, y_train, label='Champion Model')\n",
    "\n",
    "# Calculate feature importance\n",
    "feature_importance = exp.model_parts()\n",
    "feature_importance.plot(max_vars=27)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
