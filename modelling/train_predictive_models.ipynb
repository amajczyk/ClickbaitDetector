{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from classes import Word2VecModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "model_w2v_settings = return_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = Word2VecModel(model_w2v_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read preprocessed data from pickle file\n",
    "df = pd.read_pickle('data/preprocessed_titles_labels.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "title_vectors = [get_word_vectors(model_w2v, title, aggregation='mean') for title in df['title']]\n",
    "\n",
    "X = np.vstack(title_vectors)\n",
    "y = df['is_clickbait'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test stratified by y\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42, shuffle=True)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train sample model for now\n",
    "classifier = CatBoostClassifier(iterations=1000)\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predict on test data\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "\n",
    "# calculate auc and f1\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "print('AUC: ', roc_auc_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_clickbait_examples = [\n",
    "    \"You won't believe what this celebrity did!\",\n",
    "    \"Shocking secrets revealed about the latest trend!\",\n",
    "    \"This simple trick will change your life forever!\",\n",
    "    \"Is this the craziest video on the internet?\",\n",
    "    \"10 unbelievable facts that will blow your mind!\",\n",
    "    \"You'll never guess what happened next!\",\n",
    "    \"Exclusive insider information on the hottest topic!\",\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "for example in chat_clickbait_examples:\n",
    "    print(f\"{example} \\nCHANCE OF CLICKBAIT: {predict_on_text(classifier, model_w2v, example)[0][1]} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_clickbait_titles = [\n",
    "    \"Wikinews interviews Tatton Spiller, founder of political news service Simple Politics\",\n",
    "    \"NASA's OSIRIS-REx arrives in Houston, US after returning asteroid samples to Earth\",\n",
    "    \"Paedo teacher Jeremy Forrest who preyed on schoolgirl, 15, & fled to France is fired from new job after bosses find out\",]\n",
    "\n",
    "for example in non_clickbait_titles:\n",
    "    print(f\"{example} \\nCHANCE OF CLICKBAIT: {predict_on_text(classifier, model_w2v, example)[0][1]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save classifier\n",
    "import pickle\n",
    "\n",
    "pickle.dump(classifier, open('predictive_models/catboost_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read model from pickle file\n",
    "classifier = pickle.load(open('predictive_models/catboost_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_on_text(classifier, model_w2v, \"You won't believe what this celebrity did!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
