{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/adammajczyk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/adammajczyk/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/adammajczyk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/adammajczyk/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/adammajczyk/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from classes import *\n",
    "\n",
    "%run functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_clickbait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  is_clickbait\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...             1\n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...             0\n",
       "2                  Why the Truth Might Get You Fired             1\n",
       "3  15 Civilians Killed In Single US Airstrike Hav...             1\n",
       "4  Iranian woman jailed for fictional unpublished...             1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if data not saved as csv, run this\n",
    "import os\n",
    "if not os.path.exists('data/merged_titles_labels.csv'):\n",
    "    df1 = pd.read_csv('../eda/small1/labeled.csv')\n",
    "    df2 = pd.read_csv('../eda/small2/labeled.csv')\n",
    "    df3 = pd.read_csv('../eda/small3/labeled.csv')\n",
    "    df = pd.concat([df1, df2, df3], ignore_index=True).reset_index(drop=True)\n",
    "    df.to_csv('data/merged_titles_labels.csv', index=False)\n",
    "    df.head()\n",
    "else:\n",
    "    df = pd.read_csv('data/merged_titles_labels.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/adammajczyk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/adammajczyk/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/adammajczyk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/adammajczyk/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/adammajczyk/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        House Dem Aide: We Didn’t Even See Comey’s Let...\n",
      "1        FLYNN: Hillary Clinton, Big Woman on Campus - ...\n",
      "2                        Why the Truth Might Get You Fired\n",
      "3        15 Civilians Killed In Single US Airstrike Hav...\n",
      "4        Iranian woman jailed for fictional unpublished...\n",
      "                               ...                        \n",
      "75017    To Make Female Hearts Flutter in Iraq, Throw a...\n",
      "75018    British Liberal Democrat Patsy Calton, 56, die...\n",
      "75019    Drone smartphone app to help heart attack vict...\n",
      "75020    Netanyahu Urges Pope Benedict, in Israel, to D...\n",
      "75021    Computer Makers Prepare to Stake Bigger Claim ...\n",
      "Name: title, Length: 75022, dtype: object\n",
      "Removing numbers and replacing with words...\n",
      "0        House Dem Aide: We Didn’t Even See Comey’s Let...\n",
      "1        FLYNN: Hillary Clinton, Big Woman on Campus - ...\n",
      "2                        Why the Truth Might Get You Fired\n",
      "3        fifteen Civilians Killed In Single US Airstrik...\n",
      "4        Iranian woman jailed for fictional unpublished...\n",
      "                               ...                        \n",
      "75017    To Make Female Hearts Flutter in Iraq, Throw a...\n",
      "75018    British Liberal Democrat Patsy Calton, fifty-s...\n",
      "75019    Drone smartphone app to help heart attack vict...\n",
      "75020    Netanyahu Urges Pope Benedict, in Israel, to D...\n",
      "75021    Computer Makers Prepare to Stake Bigger Claim ...\n",
      "Name: title, Length: 75022, dtype: object\n",
      "Removing possesive s...\n",
      "0        House Dem Aide: We Didn’t Even See Comey Lette...\n",
      "1        FLYNN: Hillary Clinton, Big Woman on Campus - ...\n",
      "2                        Why the Truth Might Get You Fired\n",
      "3        fifteen Civilians Killed In Single US Airstrik...\n",
      "4        Iranian woman jailed for fictional unpublished...\n",
      "                               ...                        \n",
      "75017    To Make Female Hearts Flutter in Iraq, Throw a...\n",
      "75018    British Liberal Democrat Patsy Calton, fifty-s...\n",
      "75019    Drone smartphone app to help heart attack vict...\n",
      "75020    Netanyahu Urges Pope Benedict, in Israel, to D...\n",
      "75021    Computer Makers Prepare to Stake Bigger Claim ...\n",
      "Name: title, Length: 75022, dtype: object\n",
      "Expanding short versions...\n",
      "0        House Dem Aide: We Didn’t Even See Comey Lette...\n",
      "1        FLYNN: Hillary Clinton, Big Woman on Campus - ...\n",
      "2                        Why the Truth Might Get You Fired\n",
      "3        fifteen Civilians Killed In Single US Airstrik...\n",
      "4        Iranian woman jailed for fictional unpublished...\n",
      "                               ...                        \n",
      "75017    To Make Female Hearts Flutter in Iraq, Throw a...\n",
      "75018    British Liberal Democrat Patsy Calton, fifty-s...\n",
      "75019    Drone smartphone app to help heart attack vict...\n",
      "75020    Netanyahu Urges Pope Benedict, in Israel, to D...\n",
      "75021    Computer Makers Prepare to Stake Bigger Claim ...\n",
      "Name: title, Length: 75022, dtype: object\n",
      "Removing punctuation...\n",
      "0        House Dem Aide We Didn’t Even See Comey Letter...\n",
      "1        FLYNN Hillary Clinton Big Woman on Campus  Bre...\n",
      "2                        Why the Truth Might Get You Fired\n",
      "3        fifteen Civilians Killed In Single US Airstrik...\n",
      "4        Iranian woman jailed for fictional unpublished...\n",
      "                               ...                        \n",
      "75017    To Make Female Hearts Flutter in Iraq Throw a ...\n",
      "75018    British Liberal Democrat Patsy Calton fiftysix...\n",
      "75019    Drone smartphone app to help heart attack vict...\n",
      "75020    Netanyahu Urges Pope Benedict in Israel to Den...\n",
      "75021    Computer Makers Prepare to Stake Bigger Claim ...\n",
      "Name: title, Length: 75022, dtype: object\n",
      "Replacing US with USA...\n",
      "0        House Dem Aide We Didn’t Even See Comey Letter...\n",
      "1        FLYNN Hillary Clinton Big Woman on Campus  Bre...\n",
      "2                        Why the Truth Might Get You Fired\n",
      "3        fifteen Civilians Killed In Single USA Airstri...\n",
      "4        Iranian woman jailed for fictional unpublished...\n",
      "                               ...                        \n",
      "75017    To Make Female Hearts Flutter in Iraq Throw a ...\n",
      "75018    British Liberal Democrat Patsy Calton fiftysix...\n",
      "75019    Drone smartphone app to help heart attack vict...\n",
      "75020    Netanyahu Urges Pope Benedict in Israel to Den...\n",
      "75021    Computer Makers Prepare to Stake Bigger Claim ...\n",
      "Name: title, Length: 75022, dtype: object\n",
      "Tokenizing...\n",
      "0        [house, dem, aide, ’, even, see, comey, letter...\n",
      "1        [flynn, hillary, clinton, big, woman, campus, ...\n",
      "2                               [truth, might, get, fired]\n",
      "3        [fifteen, civilians, killed, single, usa, airs...\n",
      "4        [iranian, woman, jailed, fictional, unpublishe...\n",
      "                               ...                        \n",
      "75017    [make, female, hearts, flutter, iraq, throw, s...\n",
      "75018    [british, liberal, democrat, patsy, calton, fi...\n",
      "75019    [drone, smartphone, app, help, heart, attack, ...\n",
      "75020    [netanyahu, urges, pope, benedict, israel, den...\n",
      "75021    [computer, makers, prepare, stake, bigger, cla...\n",
      "Name: title, Length: 75022, dtype: object\n",
      "Lemmalizing words...\n",
      "0        [house, dem, aide, ’, even, see, comey, letter...\n",
      "1        [flynn, hillary, clinton, big, woman, campus, ...\n",
      "2                               [truth, might, get, fired]\n",
      "3        [fifteen, civilian, killed, single, usa, airst...\n",
      "4        [iranian, woman, jailed, fictional, unpublishe...\n",
      "                               ...                        \n",
      "75017    [make, female, heart, flutter, iraq, throw, shoe]\n",
      "75018    [british, liberal, democrat, patsy, calton, fi...\n",
      "75019    [drone, smartphone, app, help, heart, attack, ...\n",
      "75020    [netanyahu, urge, pope, benedict, israel, deno...\n",
      "75021    [computer, maker, prepare, stake, bigger, clai...\n",
      "Name: title, Length: 75022, dtype: object\n",
      "Removing non ascii characters...\n",
      "0        [house, dem, aide,  , even, see, comey, letter...\n",
      "1        [flynn, hillary, clinton, big, woman, campus, ...\n",
      "2                               [truth, might, get, fired]\n",
      "3        [fifteen, civilian, killed, single, usa, airst...\n",
      "4        [iranian, woman, jailed, fictional, unpublishe...\n",
      "                               ...                        \n",
      "75017    [make, female, heart, flutter, iraq, throw, shoe]\n",
      "75018    [british, liberal, democrat, patsy, calton, fi...\n",
      "75019    [drone, smartphone, app, help, heart, attack, ...\n",
      "75020    [netanyahu, urge, pope, benedict, israel, deno...\n",
      "75021    [computer, maker, prepare, stake, bigger, clai...\n",
      "Name: title, Length: 75022, dtype: object\n",
      "Removing empty titles...\n",
      "0        [house, dem, aide,  , even, see, comey, letter...\n",
      "1        [flynn, hillary, clinton, big, woman, campus, ...\n",
      "2                               [truth, might, get, fired]\n",
      "3        [fifteen, civilian, killed, single, usa, airst...\n",
      "4        [iranian, woman, jailed, fictional, unpublishe...\n",
      "                               ...                        \n",
      "75017    [make, female, heart, flutter, iraq, throw, shoe]\n",
      "75018    [british, liberal, democrat, patsy, calton, fi...\n",
      "75019    [drone, smartphone, app, help, heart, attack, ...\n",
      "75020    [netanyahu, urge, pope, benedict, israel, deno...\n",
      "75021    [computer, maker, prepare, stake, bigger, clai...\n",
      "Name: title, Length: 75016, dtype: object\n",
      "Removing stopwords one more time...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adammajczyk/Sem7/inzynierka/pracaInzynierska/modelling/functions.py:259: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['title'] = df['title'].apply(lambda x: [word for word in x if word not in stop_words])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_clickbait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[house, dem, aide,  , even, see, comey, letter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[flynn, hillary, clinton, big, woman, campus, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[truth, might, get, fired]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[fifteen, civilian, killed, single, usa, airst...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[iranian, woman, jailed, fictional, unpublishe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  is_clickbait\n",
       "0  [house, dem, aide,  , even, see, comey, letter...             1\n",
       "1  [flynn, hillary, clinton, big, woman, campus, ...             0\n",
       "2                         [truth, might, get, fired]             1\n",
       "3  [fifteen, civilian, killed, single, usa, airst...             1\n",
       "4  [iranian, woman, jailed, fictional, unpublishe...             1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run functions.py\n",
    "if not os.path.exists('data/preprocessed_titles_labels.pkl'):\n",
    "    df = preprocess_title(df, verbose=True)\n",
    "    df.to_pickle('data/preprocessed_titles_labels.pkl') \n",
    "\n",
    "else:\n",
    "    df = pd.read_pickle('data/preprocessed_titles_labels.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468341e548404c6e9c743c2fd59bbf49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce3f6810805469fb4ce64dce67e6a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predictive Models for word2vec_vs3000_win8_sg0:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/adammajczyk/Sem7/inzynierka/pracaInzynierska/modelling/select_best_word2vec.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adammajczyk/Sem7/inzynierka/pracaInzynierska/modelling/select_best_word2vec.ipynb#W1sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m results \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adammajczyk/Sem7/inzynierka/pracaInzynierska/modelling/select_best_word2vec.ipynb#W1sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m tqdm(models, desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPredictive Models for \u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adammajczyk/Sem7/inzynierka/pracaInzynierska/modelling/select_best_word2vec.ipynb#W1sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     \u001b[39m#print(f'Training {model}...')\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adammajczyk/Sem7/inzynierka/pracaInzynierska/modelling/select_best_word2vec.ipynb#W1sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     models[model]\u001b[39m.\u001b[39;49mfit(X_train_scaled, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adammajczyk/Sem7/inzynierka/pracaInzynierska/modelling/select_best_word2vec.ipynb#W1sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m models[model]\u001b[39m.\u001b[39mpredict(X_test_scaled)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adammajczyk/Sem7/inzynierka/pracaInzynierska/modelling/select_best_word2vec.ipynb#W1sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     f1 \u001b[39m=\u001b[39m f1_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/anaconda3/envs/ag/lib/python3.10/site-packages/catboost/core.py:5100\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5097\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   5098\u001b[0m     CatBoostClassifier\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m-> 5100\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline, use_best_model,\n\u001b[1;32m   5101\u001b[0m           eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period,\n\u001b[1;32m   5102\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[1;32m   5103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/ag/lib/python3.10/site-packages/catboost/core.py:2319\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2315\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2317\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2318\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[1;32m   2320\u001b[0m         train_pool,\n\u001b[1;32m   2321\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   2322\u001b[0m         params,\n\u001b[1;32m   2323\u001b[0m         allow_clear_pool,\n\u001b[1;32m   2324\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m   2325\u001b[0m     )\n\u001b[1;32m   2327\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2328\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/anaconda3/envs/ag/lib/python3.10/site-packages/catboost/core.py:1723\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   1724\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4645\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4694\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "word2vec_results = {}\n",
    "# iterate over files in word2vec_models folder\n",
    "for file in tqdm(os.listdir('word2vec_models')):\n",
    "    # check if file is a .model file\n",
    "    if file.endswith('.model'):\n",
    "\n",
    "        # load model\n",
    "        # path to model\n",
    "        path = os.path.join('word2vec_models', file)\n",
    "\n",
    "        properties = file.split('_')\n",
    "        # print(properties)\n",
    "\n",
    "        vector_size = int(properties[1][2:])\n",
    "        window_size = int(properties[2][3:])\n",
    "        is_skipgram = bool(int(properties[3][2:-6]))\n",
    "\n",
    "        settings = {\n",
    "            'model_path': path,\n",
    "            'is_skipgram' : is_skipgram,\n",
    "            'window_size' : window_size,\n",
    "            'vector_size' : vector_size, \n",
    "\n",
    "        }\n",
    "        # print(settings)\n",
    "\n",
    "        model_w2v = Word2VecModel(settings)\n",
    "        # get model name\n",
    "        model_name = file.split('.')[0]\n",
    "\n",
    "        title_vectors = [get_word_vectors(model_w2v, title, aggregation='mean') for title in df['title']]\n",
    "\n",
    "        X = np.vstack(title_vectors)\n",
    "        y = df['is_clickbait'].values\n",
    "   \n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42, shuffle=True)\n",
    "\n",
    "        # scale data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # train models\n",
    "        models = {\n",
    "            'catboost': CatBoostClassifier(verbose=False),\n",
    "            'xgboost': XGBClassifier(),\n",
    "            'lightgbm': LGBMClassifier(),\n",
    "            'knn': KNeighborsClassifier(),\n",
    "            'svm': SVC(),\n",
    "            'logreg': LogisticRegression(),\n",
    "            'randomforest': RandomForestClassifier(),\n",
    "            'decisiontree': DecisionTreeClassifier(),\n",
    "        }\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        for model in tqdm(models, desc=f'Predictive Models for {model_name}'):\n",
    "            #print(f'Training {model}...')\n",
    "            models[model].fit(X_train_scaled, y_train)\n",
    "            y_pred = models[model].predict(X_test_scaled)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred)\n",
    "            results[model] = {\n",
    "                'f1': f1,\n",
    "                'auc': auc\n",
    "            }\n",
    "            print(f'F1: {f1}')\n",
    "            print(f'AUC: {auc}')\n",
    "            print()\n",
    "        \n",
    "    word2vec_results[model_name] = results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
